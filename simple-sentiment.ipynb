{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "split = 0.2\n",
    "df = pd.read_csv('data/electronics_sample.csv')\n",
    "\n",
    "df = df[['reviewText', 'overall']].rename(columns={'reviewText': 'text', 'overall': 'label'})\n",
    "df['label'] = df['label'].astype(float)\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "df = df[:100000]\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=split, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_83205/1168182555.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace(r'[^a-z0-9\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "# Normalize the text\n",
    "def normalize(df):\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    df['text'] = df['text'].str.replace(r'[^a-z0-9\\s]', '')\n",
    "    return df\n",
    "\n",
    "df_train = normalize(df_train)\n",
    "df_test = normalize(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/christianjensen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Noise reduction\n",
    "# Remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(lambda x: remove_html_tags(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x: remove_html_tags(x))\n",
    "\n",
    "# Expand contractions\n",
    "import contractions\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(lambda x: expand_contractions(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x: expand_contractions(x))\n",
    "\n",
    "# Remove stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(lambda x: remove_stopwords(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/christianjensen/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK Sentiment Analysis\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    return sid.polarity_scores(text)['compound']\n",
    "\n",
    "df_train['sentiment'] = df_train['text'].apply(lambda x: get_sentiment(x))\n",
    "df_test['sentiment'] = df_test['text'].apply(lambda x: get_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of characters and words in the text\n",
    "df_train['num_chars'] = df_train['text'].apply(lambda x: len(x))\n",
    "df_train['num_words'] = df_train['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df_test['num_chars'] = df_test['text'].apply(lambda x: len(x))\n",
    "df_test['num_words'] = df_test['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words with Doc2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(df_train['text'].apply(lambda x: x.split()))]\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "def get_doc2vec(text):\n",
    "    return model.infer_vector(text.split())\n",
    "\n",
    "df_train['doc2vec'] = df_train['text'].apply(lambda x: get_doc2vec(x))\n",
    "df_test['doc2vec'] = df_test['text'].apply(lambda x: get_doc2vec(x))\n",
    "\n",
    "# Save Doc2Vec model\n",
    "model.save('models/doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF with words appearing in at least 10 documents\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "vectorizer.fit(df_train['text'])\n",
    "\n",
    "def get_tfidf(text):\n",
    "    return vectorizer.transform([text]).toarray()[0]\n",
    "\n",
    "df_train['tfidf'] = df_train['text'].apply(lambda x: get_tfidf(x))\n",
    "df_test['tfidf'] = df_test['text'].apply(lambda x: get_tfidf(x))\n",
    "\n",
    "# Save TF-IDF model\n",
    "import pickle\n",
    "\n",
    "pickle.dump(vectorizer, open('models/tfidf.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>doc2vec</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17957</th>\n",
       "      <td>glamorous</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.022869734, 0.16723807, 0.14389996, -0.02233...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>three stars</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.023132347, 0.15524653, 0.04315128, -0.10118...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19500</th>\n",
       "      <td>sent camera back used could new camera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.19933283, 0.062481225, 0.11008031, -0.10843...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5091</th>\n",
       "      <td>good laptop</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.07510884, 0.05769736, 0.0022005695, -0.0226...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12777</th>\n",
       "      <td>great device use locally</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.15382144, -0.04097546, 0.09185709, -0.21206...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text  label  sentiment  num_chars  \\\n",
       "17957                               glamorous    4.0     0.5106          9   \n",
       "8390                              three stars    3.0     0.0000         11   \n",
       "19500  sent camera back used could new camera    5.0     0.0000         38   \n",
       "5091                              good laptop    4.0     0.4404         11   \n",
       "12777                great device use locally    5.0     0.6249         24   \n",
       "\n",
       "       num_words                                            doc2vec  \\\n",
       "17957          1  [0.022869734, 0.16723807, 0.14389996, -0.02233...   \n",
       "8390           2  [0.023132347, 0.15524653, 0.04315128, -0.10118...   \n",
       "19500          7  [0.19933283, 0.062481225, 0.11008031, -0.10843...   \n",
       "5091           2  [0.07510884, 0.05769736, 0.0022005695, -0.0226...   \n",
       "12777          4  [0.15382144, -0.04097546, 0.09185709, -0.21206...   \n",
       "\n",
       "                                                   tfidf  \n",
       "17957  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8390   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "19500  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5091   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "12777  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features and labels\n",
    "X_train = df_train[['sentiment', 'num_chars', 'num_words', 'doc2vec', 'tfidf']].values.tolist()\n",
    "X_train = [np.concatenate(([x[0]], [x[1]], [x[2]], x[3], x[4])) for x in X_train]\n",
    "\n",
    "X_test = df_test[['sentiment', 'num_chars', 'num_words', 'doc2vec', 'tfidf']].values.tolist()\n",
    "X_test = [np.concatenate(([x[0]], [x[1]], [x[2]], x[3], x[4])) for x in X_test]\n",
    "\n",
    "y_train = df_train['label'].values.tolist()\n",
    "y_test = df_test['label'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram of predicted values for true values 1-5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(1, 6):\n",
    "    plt.hist(y_pred[np.array(y_test) == i], label=str(i), alpha=0.5, bins=40)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_83205/437073820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Model: {type(model).__name__} - RMSE:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_83205/3459538194.py\u001b[0m in \u001b[0;36mtrain_evaluate_model\u001b[0;34m(model, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5728\u001b[0m             \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5730\u001b[0;31m         return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   5731\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5732\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2337\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2339\u001b[0;31m         train_params = self._prepare_train_params(\n\u001b[0m\u001b[1;32m   2340\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m             \u001b[0mpairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2218\u001b[0m         \u001b[0membedding_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embedding_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2220\u001b[0;31m         train_pool = _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs,\n\u001b[0m\u001b[1;32m   2221\u001b[0m                                        \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m                                        baseline, column_description)\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_build_train_pool\u001b[0;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m         train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, embedding_features=embedding_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n\u001b[0m\u001b[1;32m   1439\u001b[0m                           group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    790\u001b[0m                     )\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m                 self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0m\u001b[1;32m    793\u001b[0m                            group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m    794\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_tags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m             \u001b[0mfeature_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_transform_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m         self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0m\u001b[1;32m   1420\u001b[0m                         group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_objects_order_layout_pool\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._set_label_objects_order\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "    CatBoostRegressor(iterations=100, loss_function='RMSE', verbose=False),\n",
    "    XGBRegressor(n_estimators=100, objective='reg:squarederror'),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    print(f'Model: {type(model).__name__} - RMSE:', train_evaluate_model(model, X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.411876\n",
      "0:\tlearn: 1.3060128\ttotal: 75ms\tremaining: 7.42s\n",
      "1:\tlearn: 1.2450353\ttotal: 125ms\tremaining: 6.12s\n",
      "2:\tlearn: 1.2122930\ttotal: 170ms\tremaining: 5.5s\n",
      "3:\tlearn: 1.1949735\ttotal: 221ms\tremaining: 5.3s\n",
      "4:\tlearn: 1.1857154\ttotal: 271ms\tremaining: 5.14s\n",
      "5:\tlearn: 1.1736366\ttotal: 316ms\tremaining: 4.95s\n",
      "6:\tlearn: 1.1672216\ttotal: 360ms\tremaining: 4.79s\n",
      "7:\tlearn: 1.1603217\ttotal: 406ms\tremaining: 4.66s\n",
      "8:\tlearn: 1.1529148\ttotal: 457ms\tremaining: 4.62s\n",
      "9:\tlearn: 1.1481457\ttotal: 498ms\tremaining: 4.48s\n",
      "10:\tlearn: 1.1430092\ttotal: 538ms\tremaining: 4.35s\n",
      "11:\tlearn: 1.1382815\ttotal: 580ms\tremaining: 4.25s\n",
      "12:\tlearn: 1.1338948\ttotal: 622ms\tremaining: 4.16s\n",
      "13:\tlearn: 1.1304513\ttotal: 668ms\tremaining: 4.1s\n",
      "14:\tlearn: 1.1269523\ttotal: 719ms\tremaining: 4.07s\n",
      "15:\tlearn: 1.1226282\ttotal: 770ms\tremaining: 4.04s\n",
      "16:\tlearn: 1.1191613\ttotal: 813ms\tremaining: 3.97s\n",
      "17:\tlearn: 1.1165969\ttotal: 860ms\tremaining: 3.92s\n",
      "18:\tlearn: 1.1138278\ttotal: 913ms\tremaining: 3.89s\n",
      "19:\tlearn: 1.1113121\ttotal: 964ms\tremaining: 3.86s\n",
      "20:\tlearn: 1.1082404\ttotal: 1.01s\tremaining: 3.82s\n",
      "21:\tlearn: 1.1057448\ttotal: 1.06s\tremaining: 3.77s\n",
      "22:\tlearn: 1.1026089\ttotal: 1.11s\tremaining: 3.73s\n",
      "23:\tlearn: 1.1002417\ttotal: 1.17s\tremaining: 3.7s\n",
      "24:\tlearn: 1.0974086\ttotal: 1.22s\tremaining: 3.67s\n",
      "25:\tlearn: 1.0945618\ttotal: 1.28s\tremaining: 3.65s\n",
      "26:\tlearn: 1.0920733\ttotal: 1.34s\tremaining: 3.62s\n",
      "27:\tlearn: 1.0893323\ttotal: 1.39s\tremaining: 3.56s\n",
      "28:\tlearn: 1.0869414\ttotal: 1.43s\tremaining: 3.5s\n",
      "29:\tlearn: 1.0842787\ttotal: 1.48s\tremaining: 3.45s\n",
      "30:\tlearn: 1.0781632\ttotal: 1.54s\tremaining: 3.43s\n",
      "31:\tlearn: 1.0755146\ttotal: 1.61s\tremaining: 3.42s\n",
      "32:\tlearn: 1.0727724\ttotal: 1.66s\tremaining: 3.36s\n",
      "33:\tlearn: 1.0701012\ttotal: 1.7s\tremaining: 3.31s\n",
      "34:\tlearn: 1.0680025\ttotal: 1.75s\tremaining: 3.24s\n",
      "35:\tlearn: 1.0657888\ttotal: 1.79s\tremaining: 3.19s\n",
      "36:\tlearn: 1.0636973\ttotal: 1.84s\tremaining: 3.13s\n",
      "37:\tlearn: 1.0615697\ttotal: 1.88s\tremaining: 3.07s\n",
      "38:\tlearn: 1.0598280\ttotal: 1.93s\tremaining: 3.02s\n",
      "39:\tlearn: 1.0578093\ttotal: 1.98s\tremaining: 2.96s\n",
      "40:\tlearn: 1.0558996\ttotal: 2.03s\tremaining: 2.92s\n",
      "41:\tlearn: 1.0538622\ttotal: 2.09s\tremaining: 2.89s\n",
      "42:\tlearn: 1.0518450\ttotal: 2.15s\tremaining: 2.85s\n",
      "43:\tlearn: 1.0500589\ttotal: 2.32s\tremaining: 2.96s\n",
      "44:\tlearn: 1.0481205\ttotal: 2.46s\tremaining: 3.01s\n",
      "45:\tlearn: 1.0463968\ttotal: 2.52s\tremaining: 2.96s\n",
      "46:\tlearn: 1.0447943\ttotal: 2.62s\tremaining: 2.95s\n",
      "47:\tlearn: 1.0429468\ttotal: 2.67s\tremaining: 2.9s\n",
      "48:\tlearn: 1.0411038\ttotal: 2.72s\tremaining: 2.83s\n",
      "49:\tlearn: 1.0398227\ttotal: 2.78s\tremaining: 2.78s\n",
      "50:\tlearn: 1.0373715\ttotal: 2.86s\tremaining: 2.75s\n",
      "51:\tlearn: 1.0362891\ttotal: 2.92s\tremaining: 2.69s\n",
      "52:\tlearn: 1.0347922\ttotal: 2.96s\tremaining: 2.63s\n",
      "53:\tlearn: 1.0333729\ttotal: 3.01s\tremaining: 2.57s\n",
      "54:\tlearn: 1.0323343\ttotal: 3.07s\tremaining: 2.51s\n",
      "55:\tlearn: 1.0303217\ttotal: 3.12s\tremaining: 2.45s\n",
      "56:\tlearn: 1.0291046\ttotal: 3.19s\tremaining: 2.41s\n",
      "57:\tlearn: 1.0274281\ttotal: 3.26s\tremaining: 2.36s\n",
      "58:\tlearn: 1.0248159\ttotal: 3.34s\tremaining: 2.32s\n",
      "59:\tlearn: 1.0226932\ttotal: 3.4s\tremaining: 2.27s\n",
      "60:\tlearn: 1.0215377\ttotal: 3.46s\tremaining: 2.21s\n",
      "61:\tlearn: 1.0201698\ttotal: 3.54s\tremaining: 2.17s\n",
      "62:\tlearn: 1.0190175\ttotal: 3.65s\tremaining: 2.15s\n",
      "63:\tlearn: 1.0174159\ttotal: 3.77s\tremaining: 2.12s\n",
      "64:\tlearn: 1.0162116\ttotal: 4.02s\tremaining: 2.16s\n",
      "65:\tlearn: 1.0153409\ttotal: 4.17s\tremaining: 2.15s\n",
      "66:\tlearn: 1.0147557\ttotal: 4.37s\tremaining: 2.15s\n",
      "67:\tlearn: 1.0133080\ttotal: 4.55s\tremaining: 2.14s\n",
      "68:\tlearn: 1.0109782\ttotal: 4.74s\tremaining: 2.13s\n",
      "69:\tlearn: 1.0098254\ttotal: 4.92s\tremaining: 2.11s\n",
      "70:\tlearn: 1.0082377\ttotal: 5.06s\tremaining: 2.07s\n",
      "71:\tlearn: 1.0070748\ttotal: 5.22s\tremaining: 2.03s\n",
      "72:\tlearn: 1.0060606\ttotal: 5.52s\tremaining: 2.04s\n",
      "73:\tlearn: 1.0045859\ttotal: 5.65s\tremaining: 1.98s\n",
      "74:\tlearn: 1.0035654\ttotal: 5.81s\tremaining: 1.94s\n",
      "75:\tlearn: 1.0017732\ttotal: 5.95s\tremaining: 1.88s\n",
      "76:\tlearn: 0.9998755\ttotal: 6.11s\tremaining: 1.83s\n",
      "77:\tlearn: 0.9989091\ttotal: 6.25s\tremaining: 1.76s\n",
      "78:\tlearn: 0.9978020\ttotal: 6.46s\tremaining: 1.72s\n",
      "79:\tlearn: 0.9964155\ttotal: 6.59s\tremaining: 1.65s\n",
      "80:\tlearn: 0.9960972\ttotal: 6.73s\tremaining: 1.58s\n",
      "81:\tlearn: 0.9951786\ttotal: 6.9s\tremaining: 1.51s\n",
      "82:\tlearn: 0.9937334\ttotal: 7.06s\tremaining: 1.45s\n",
      "83:\tlearn: 0.9921455\ttotal: 7.22s\tremaining: 1.37s\n",
      "84:\tlearn: 0.9911416\ttotal: 7.35s\tremaining: 1.3s\n",
      "85:\tlearn: 0.9903609\ttotal: 7.52s\tremaining: 1.22s\n",
      "86:\tlearn: 0.9886782\ttotal: 7.68s\tremaining: 1.15s\n",
      "87:\tlearn: 0.9874106\ttotal: 7.84s\tremaining: 1.07s\n",
      "88:\tlearn: 0.9862026\ttotal: 7.96s\tremaining: 984ms\n",
      "89:\tlearn: 0.9852643\ttotal: 8.03s\tremaining: 893ms\n",
      "90:\tlearn: 0.9845953\ttotal: 8.17s\tremaining: 808ms\n",
      "91:\tlearn: 0.9833667\ttotal: 8.37s\tremaining: 728ms\n",
      "92:\tlearn: 0.9822401\ttotal: 8.49s\tremaining: 639ms\n",
      "93:\tlearn: 0.9813315\ttotal: 8.61s\tremaining: 550ms\n",
      "94:\tlearn: 0.9805094\ttotal: 8.71s\tremaining: 458ms\n",
      "95:\tlearn: 0.9790164\ttotal: 8.87s\tremaining: 370ms\n",
      "96:\tlearn: 0.9775204\ttotal: 8.99s\tremaining: 278ms\n",
      "97:\tlearn: 0.9768449\ttotal: 9.13s\tremaining: 186ms\n",
      "98:\tlearn: 0.9755284\ttotal: 9.24s\tremaining: 93.3ms\n",
      "99:\tlearn: 0.9745645\ttotal: 9.35s\tremaining: 0us\n",
      "RMSE: 1.069134411000966\n"
     ]
    }
   ],
   "source": [
    "# Train CATBoost model\n",
    "model = CatBoostRegressor(iterations=100, loss_function='RMSE')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "\n",
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/christianjensen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/christianjensen/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import contractions\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    return sid.polarity_scores(text)['compound']\n",
    "\n",
    "# Normalize the text\n",
    "def normalize(df):\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    df['text'] = df['text'].str.replace(r'[^a-z0-9\\s]', '')\n",
    "    return df\n",
    "\n",
    "# Noise reduction\n",
    "# Remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "\n",
    "# Expand contractions\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "\n",
    "\n",
    "# Load Doc2Vec model\n",
    "doc2vec = Doc2Vec.load('models/doc2vec.model')\n",
    "\n",
    "def get_doc2vec(text):\n",
    "    return doc2vec.infer_vector(text.split())\n",
    "\n",
    "\n",
    "# Load TF-IDF model\n",
    "tfidf = pickle.load(open('models/tfidf.pickle', 'rb'))\n",
    "\n",
    "def get_tfidf(text):\n",
    "    return tfidf.transform([text]).toarray()[0]\n",
    "\n",
    "\n",
    "# Load model\n",
    "model = pickle.load(open('model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_86378/3748208050.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace(r'[^a-z0-9\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "reviews = ['This is a great product', 'This is a bad product', 'This is a good product', 'This is a terrible product', 'Wow this is amazing'] * 200\n",
    "\n",
    "\n",
    "df = pd.DataFrame(reviews, columns=['text'])\n",
    "\n",
    "df = normalize(df)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: remove_html_tags(x))\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: expand_contractions(x))\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "df['num_chars'] = df['text'].apply(lambda x: len(x))\n",
    "df['num_words'] = df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df['sentiment'] = df['text'].apply(lambda x: get_sentiment(x))\n",
    "\n",
    "df['doc2vec'] = df['text'].apply(lambda x: get_doc2vec(x))\n",
    "df['tfidf'] = df['text'].apply(lambda x: get_tfidf(x))\n",
    "\n",
    "# Create the features and labels\n",
    "X = df[['sentiment', 'num_chars', 'num_words', 'doc2vec', 'tfidf']].values.tolist()\n",
    "X = [np.concatenate(([x[0]], [x[1]], [x[2]], x[3], x[4])) for x in X]\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.15790312, 1.84379287, 3.45454692, 1.57379921, 4.32496566,\n",
       "       4.15790312, 1.8321106 , 3.45454692, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.82251456, 3.45454692, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.82251456, 3.45844162, 1.63987402, 4.32496566,\n",
       "       4.15258971, 1.84379287, 3.47594675, 1.57379921, 4.32496566,\n",
       "       4.14247075, 1.84379287, 3.44923351, 1.57379921, 4.32496566,\n",
       "       4.15790312, 1.85338891, 3.45873019, 1.58579791, 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.44923351, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.4640436 , 1.5684858 , 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.44923351, 1.58579791, 4.30339878,\n",
       "       4.15790312, 1.83160116, 3.45454692, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.85338891, 3.44894495, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.83160116, 3.44923351, 1.58048449, 4.30368735,\n",
       "       4.15790312, 1.85338891, 3.44894495, 1.57379921, 4.32496566,\n",
       "       4.15790312, 1.84379287, 3.44894495, 1.58048449, 4.32467709,\n",
       "       4.15790312, 1.84379287, 3.45425836, 1.5684858 , 4.30339878,\n",
       "       4.15790312, 1.82251456, 3.4640436 , 1.57379921, 4.30368735,\n",
       "       4.12474598, 1.85338891, 3.45348568, 1.5684858 , 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.44923351, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.85338891, 3.45348568, 1.58579791, 4.32496566,\n",
       "       4.15790312, 1.82251456, 3.44894495, 1.58048449, 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.46113666, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.85338891, 3.47623532, 1.57379921, 4.30368735,\n",
       "       4.14840644, 1.84379287, 3.44923351, 1.57379921, 4.30339878,\n",
       "       4.14778416, 1.85338891, 3.44923351, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.83160116, 3.46375504, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.82251456, 3.44894495, 1.5684858 , 4.32467709,\n",
       "       4.15790312, 1.82251456, 3.53667018, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.54198359, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.83160116, 3.46645008, 1.58579791, 4.27024165,\n",
       "       4.15790312, 1.81032285, 3.44861123, 1.57379921, 4.27024165,\n",
       "       4.15790312, 1.84379287, 3.45454692, 1.57379921, 4.30339878,\n",
       "       4.14840644, 1.85338891, 3.44923351, 1.58048449, 4.32496566,\n",
       "       4.15790312, 1.84379287, 3.44894495, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.81032285, 3.44923351, 1.5684858 , 4.30339878,\n",
       "       4.14840644, 1.84379287, 3.46375504, 1.58579791, 4.32467709,\n",
       "       4.15790312, 1.85338891, 3.45454692, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.45454692, 1.57379921, 4.32496566,\n",
       "       4.15790312, 1.84379287, 3.44923351, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.46582779, 1.57379921, 4.30812964,\n",
       "       4.15790312, 1.84379287, 3.53667018, 1.58579791, 4.32496566,\n",
       "       4.15790312, 1.84379287, 3.44923351, 1.57379921, 4.30368735,\n",
       "       4.14840644, 1.84512334, 3.4640436 , 1.57379921, 4.27024165,\n",
       "       4.15258971, 1.84379287, 3.47623532, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.85338891, 3.44923351, 1.57379921, 4.39112401,\n",
       "       4.14778416, 1.83160116, 3.46645008, 1.62238564, 4.32496566,\n",
       "       4.15790312, 1.87859337, 3.45377424, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.45454692, 1.58579791, 4.30368735,\n",
       "       4.15790312, 1.87703005, 3.46127166, 1.5684858 , 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.45844162, 1.57379921, 4.32496566,\n",
       "       4.15790312, 1.82251456, 3.44923351, 1.5684858 , 4.30368735,\n",
       "       4.15790312, 1.85338891, 3.44923351, 1.57379921, 4.32496566,\n",
       "       4.15790312, 1.82251456, 3.46673864, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.84379287, 3.46375504, 1.5684858 , 4.30812964,\n",
       "       4.14840644, 1.84379287, 3.4640436 , 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.8321106 , 3.54198359, 1.58579791, 4.30368735,\n",
       "       4.14840644, 1.84379287, 3.44923351, 1.5684858 , 4.30368735,\n",
       "       4.15790312, 1.85338891, 3.54136131, 1.61871866, 4.32467709,\n",
       "       4.15790312, 1.85338891, 3.44894495, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.84379287, 3.54616685, 1.58579791, 4.32496566,\n",
       "       4.15790312, 1.82251456, 3.53667018, 1.57379921, 4.39112401,\n",
       "       4.14840644, 1.85338891, 3.45873019, 1.57379921, 4.30368735,\n",
       "       4.16990181, 1.83160116, 3.45873019, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.84379287, 3.45873019, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.81032285, 3.45873019, 1.58579791, 4.32467709,\n",
       "       4.15790312, 1.83160116, 3.44923351, 1.58579791, 4.32496566,\n",
       "       4.15790312, 1.85338891, 3.44923351, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.82251456, 3.54886189, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.8321106 , 3.45454692, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.83160116, 3.44894495, 1.57379921, 4.32496566,\n",
       "       4.12474598, 1.84379287, 3.44923351, 1.5684858 , 4.39112401,\n",
       "       4.15790312, 1.82251456, 3.44923351, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.88871232, 3.45454692, 1.57379921, 4.27024165,\n",
       "       4.12474598, 1.84379287, 3.44894495, 1.60328629, 4.32496566,\n",
       "       4.15790312, 1.84379287, 3.54198359, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.83160116, 3.45454692, 1.57379921, 4.39112401,\n",
       "       4.14309303, 1.83160116, 3.44894495, 1.5684858 , 4.30339878,\n",
       "       4.15790312, 1.85338891, 3.46142523, 1.58579791, 4.32496566,\n",
       "       4.11943257, 1.81032285, 3.44923351, 1.64518744, 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.44894495, 1.57379921, 4.32940795,\n",
       "       4.11462702, 1.84379287, 3.44894495, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.85338891, 3.46113666, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.44894495, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.8321106 , 3.45908765, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.45454692, 1.57379921, 4.39112401,\n",
       "       4.14778416, 1.82251456, 3.45454692, 1.54630338, 4.32467709,\n",
       "       4.15790312, 1.84379287, 3.45454692, 1.58048449, 4.30368735,\n",
       "       4.15790312, 1.83160116, 3.45454692, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.8321106 , 3.45425836, 1.58048449, 4.41240232,\n",
       "       4.15790312, 1.84379287, 3.44894495, 1.57379921, 4.32496566,\n",
       "       4.15790312, 1.84379287, 3.45898921, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.82251456, 3.56367198, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.8321106 , 3.46142523, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.83160116, 3.44894495, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.44923351, 1.58579791, 4.32496566,\n",
       "       4.15790312, 1.83160116, 3.44923351, 1.57379921, 4.30368735,\n",
       "       4.14778416, 1.84379287, 3.54136131, 1.57379921, 4.30339878,\n",
       "       4.13143126, 1.84379287, 3.45454692, 1.5684858 , 4.30812964,\n",
       "       4.15790312, 1.85338891, 3.44894495, 1.5684858 , 4.32467709,\n",
       "       4.15790312, 1.82251456, 3.45454692, 1.5684858 , 4.30368735,\n",
       "       4.15790312, 1.85338891, 3.44923351, 1.62540394, 4.32496566,\n",
       "       4.15790312, 1.85338891, 3.46673864, 1.5684858 , 4.27024165,\n",
       "       4.15790312, 1.85338891, 3.52758358, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.82251456, 3.45873019, 1.5684858 , 4.30339878,\n",
       "       4.14840644, 1.83160116, 3.45454692, 1.57379921, 4.32496566,\n",
       "       4.15790312, 1.84379287, 3.45425836, 1.57379921, 4.41240232,\n",
       "       4.15790312, 1.82251456, 3.44923351, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.83160116, 3.44894495, 1.60328629, 4.32467709,\n",
       "       4.14840644, 1.84379287, 3.47118093, 1.5684858 , 4.27053021,\n",
       "       4.15790312, 1.85338891, 3.45454692, 1.6553064 , 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.42766664, 1.5684858 , 4.32496566,\n",
       "       4.15790312, 1.83160116, 3.45454692, 1.57379921, 4.30368735,\n",
       "       4.15258971, 1.83160116, 3.45425836, 1.58579791, 4.32496566,\n",
       "       4.15258971, 1.8321106 , 3.45425836, 1.58579791, 4.32467709,\n",
       "       4.12474598, 1.84379287, 3.44923351, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.44923351, 1.57379921, 4.32496566,\n",
       "       4.15790312, 1.84379287, 3.44923351, 1.5684858 , 4.27053021,\n",
       "       4.15790312, 1.84379287, 3.54136131, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.4640436 , 1.54383081, 4.32496566,\n",
       "       4.15790312, 1.84379287, 3.44923351, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.85338891, 3.44894495, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.83160116, 3.54198359, 1.57379921, 4.30368735,\n",
       "       4.12474598, 1.84379287, 3.46645008, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.81032285, 3.46113666, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.83160116, 3.44861123, 1.58579791, 4.30368735,\n",
       "       4.15790312, 1.85338891, 3.44923351, 1.57379921, 4.30339878,\n",
       "       4.15258971, 1.83160116, 3.45425836, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.83160116, 3.42733292, 1.57379921, 4.32496566,\n",
       "       4.15790312, 1.81032285, 3.44894495, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.85338891, 3.44923351, 1.58579791, 4.32496566,\n",
       "       4.15790312, 1.85338891, 3.44832266, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.85338891, 3.44894495, 1.57379921, 4.41240232,\n",
       "       4.14840644, 1.84379287, 3.44923351, 1.58579791, 4.27024165,\n",
       "       4.15790312, 1.84379287, 3.45454692, 1.57379921, 4.27024165,\n",
       "       4.15790312, 1.84379287, 3.44894495, 1.5684858 , 4.30368735,\n",
       "       4.12474598, 1.81032285, 3.46582779, 1.57379921, 4.32467709,\n",
       "       4.11943257, 1.85338891, 3.44923351, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.82251456, 3.44894495, 1.57379921, 4.39112401,\n",
       "       4.12474598, 1.84379287, 3.47623532, 1.57379921, 4.32467709,\n",
       "       4.14840644, 1.85338891, 3.46113666, 1.57379921, 4.30368735,\n",
       "       4.12474598, 1.82251456, 3.44894495, 1.58579791, 4.30368735,\n",
       "       4.15258971, 1.85338891, 3.4640436 , 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.85338891, 3.44923351, 1.5684858 , 4.32467709,\n",
       "       4.15790312, 1.82251456, 3.45425836, 1.5684858 , 4.27053021,\n",
       "       4.15790312, 1.85338891, 3.46142523, 1.58579791, 4.30339878,\n",
       "       4.15790312, 1.8321106 , 3.47099081, 1.58048449, 4.32496566,\n",
       "       4.14840644, 1.85338891, 3.4536758 , 1.58048449, 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.46142523, 1.5684858 , 4.30339878,\n",
       "       4.12474598, 1.82251456, 3.4640436 , 1.57379921, 4.32496566,\n",
       "       4.15258971, 1.81032285, 3.44923351, 1.5684858 , 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.54198359, 1.5684858 , 4.30339878,\n",
       "       4.12474598, 1.84379287, 3.45454692, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.83160116, 3.45454692, 1.57379921, 4.32467709,\n",
       "       4.12474598, 1.89830836, 3.4640436 , 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.83160116, 3.44923351, 1.57379921, 4.27024165,\n",
       "       4.15790312, 1.85338891, 3.46317248, 1.60328629, 4.32467709,\n",
       "       4.15790312, 1.84379287, 3.53667018, 1.57379921, 4.30339878,\n",
       "       4.13143126, 1.8881894 , 3.44861123, 1.58579791, 4.27024165,\n",
       "       4.15790312, 1.84379287, 3.46113666, 1.5684858 , 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.46113666, 1.54630338, 4.39112401,\n",
       "       4.15790312, 1.82251456, 3.44894495, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.85338891, 3.45454692, 1.5684858 , 4.30339878,\n",
       "       4.14247075, 1.85338891, 3.53667018, 1.62238564, 4.30368735,\n",
       "       4.15790312, 1.8321106 , 3.46142523, 1.57379921, 4.32496566,\n",
       "       4.15790312, 1.83160116, 3.44894495, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.54886189, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.82251456, 3.45377424, 1.57379921, 4.32496566,\n",
       "       4.14840644, 1.84379287, 3.44923351, 1.5684858 , 4.30339878,\n",
       "       4.12474598, 1.83160116, 3.55148027, 1.57379921, 4.32467709,\n",
       "       4.12474598, 1.85338891, 3.45454692, 1.57379921, 4.31539748,\n",
       "       4.15790312, 1.83160116, 3.45454692, 1.57379921, 4.39112401,\n",
       "       4.15790312, 1.85338891, 3.46142523, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.44923351, 1.54383081, 4.30368735,\n",
       "       4.15790312, 1.83160116, 3.44894495, 1.5684858 , 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.55148027, 1.58579791, 4.30339878,\n",
       "       4.15258971, 1.84379287, 3.45425836, 1.61871866, 4.32496566,\n",
       "       4.15790312, 1.85338891, 3.44894495, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.83160116, 3.44894495, 1.57379921, 4.29151996,\n",
       "       4.15258971, 1.84379287, 3.54198359, 1.5684858 , 4.30368735,\n",
       "       4.15790312, 1.83160116, 3.44923351, 1.54383081, 4.32496566,\n",
       "       4.15790312, 1.85338891, 3.45377424, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.8321106 , 3.45454692, 1.57379921, 4.27024165,\n",
       "       4.14309303, 1.84379287, 3.54616685, 1.57379921, 4.32467709,\n",
       "       4.15790312, 1.84379287, 3.44923351, 1.57379921, 4.30368735,\n",
       "       4.14840644, 1.84379287, 3.44439909, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.85338891, 3.46142523, 1.5684858 , 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.45454692, 1.57379921, 4.39112401,\n",
       "       4.14840644, 1.84379287, 3.46113666, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.44894495, 1.57379921, 4.30368735,\n",
       "       4.11943257, 1.8321106 , 3.4656774 , 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.83160116, 3.45454692, 1.58048449, 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.45454692, 1.61707223, 4.30339878,\n",
       "       4.15790312, 1.8321106 , 3.44894495, 1.57379921, 4.30368735,\n",
       "       4.14840644, 1.84379287, 3.44894495, 1.57379921, 4.30368735,\n",
       "       4.15790312, 1.84379287, 3.45425836, 1.57379921, 4.30368735,\n",
       "       4.14840644, 1.83160116, 3.44923351, 1.57379921, 4.30339878,\n",
       "       4.15790312, 1.84379287, 3.53604789, 1.57379921, 4.39112401,\n",
       "       4.14840644, 1.84379287, 3.45425836, 1.60328629, 4.30368735,\n",
       "       4.15790312, 1.82251456, 3.45454692, 1.57379921, 4.32496566,\n",
       "       4.14840644, 1.84379287, 3.45454692, 1.5684858 , 4.32496566])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
